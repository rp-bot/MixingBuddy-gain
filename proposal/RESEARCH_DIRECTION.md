Toward Agentic Automatic Mixing: Differential Multi-Track Gain Analysis for AI Mixing Assistance

1. Introduction & Problem Statement

While current Audio-Language Models (ALMs) show impressive capabilities in general audio understanding, they are primarily trained on descriptive tasks like captioning or classification. When applied to music mixing, these generalist models lack the specific, evaluative ability to provide actionable advice. As confirmed by user studies in the

MixAssist paper, this results in assistants that struggle with the relational and qualitative reasoning essential to the mixing process. This research aims to address this gap by proposing a novel training methodology to create a more effective AI mixing assistant.

2. Proposed Method: Differential Analysis

This project will pivot from the standard single-input advisory task to a differential, multi-track analysis framework. Instead of asking a model "What is wrong with this mix?", we will train it to compare an unbalanced set of tracks to a balanced reference set. The model's task will be to generate a textual explanation of the specific gain adjustments required to resolve the balance issues. This reframes the problem from a descriptive task to a comparative, cause-and-effect reasoning task that more closely mirrors an audio engineer's workflow.

3. Methodology

Dataset: We will programmatically create a new, synthetic dataset for this task. The source audio will be the high-quality multi-track stems from the MUSDB18 dataset.

Each data instance will be a triplet: (Unbalanced Track Set A, Balanced Track Set B, Text Explanation).

"Problem" sets (Version A) will be generated by programmatically altering the gain of one or more stems from the original MUSDB mixes.

"Solution" sets (Version B) will be the original stems at their professionally mixed levels.

The

Text Explanation will be a templated description of the specific gain change needed to get from A to B. This synthetic data generation strategy is a common and effective approach in modern ALM development.

Model and Fine-Tuning: We will employ a state-of-the-art ALM architecture capable of handling multiple audio inputs, such as those described in the Qwen-Audio or Audio Flamingo papers. The model will be fine-tuned using a parameter-efficient method like LoRA, which is proven to be effective for this type of adaptation.

4. Evaluation and Expected Contribution

The primary hypothesis is that our differential, multi-track model will provide more specific and helpful gain-balancing advice than a standard single-mix advisory model.

Comparative Evaluation: We will conduct a rigorous evaluation against a baseline model trained using the single-input method from MixAssist.

Multi-Faceted Approach: Following the robust evaluation framework in the MixAssist paper, we will use both automated

LLM-as-a-Judge assessments and human preference studies involving music producers.

The expected contribution of this research is a novel and effective methodology for training AI assistants that can reason about the relational properties of a music mix. By focusing on differential analysis of multi-track audio, this work aims to produce a more capable "Mixing Buddy" that provides precise, actionable, and context-aware guidance.
