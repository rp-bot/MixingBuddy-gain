\section*{Proposed Method}
\label{sec:proposed_method}

This research introduces a novel framework for fine-tuning an Audio-Language Model (ALM) to generate gain-balancing advice for music mixing. 
The approach conditions the model on a designated anchor track to learn relational understanding of multi-track audio levels, emulating how human engineers establish mix foundations.

\subsection*{Data Preprocessing and Dataset Creation}
We will utilize the MUSDB18 dataset \cite{Rafii_Liutkus_St√∂ter_Mimilakis_Bittner_2019} to create a structured training dataset in JSONL format.

Each training instance will contain a prompt with text instruction for gain-balancing advice, audio data with anchor track and other track stems, and a response with generated mixing advice describing gain relationships.
We will generate training examples through both programmatic annotation. 
For each anchor track and other tracks combination, we will create annotations describing the ideal gain relationship (e.g., ``Relative to the drums, the vocal stem is well-balanced and sits clearly on top of the mix'') and corrective advice for imbalanced cases (e.g., ``The vocal stem is too loud relative to the drums; decrease its gain for better balance''). 
We will evaluate different anchor selection strategies and their impact on model performance across various musical contexts and genres.

\subsection*{Model Architecture and Training Strategy}
We will employ Qwen-Audio \cite{Chu_Xu_Zhou_Yang_Zhang_Yan_Zhou_Zhou_2023} as the primary base model, while also exploring other pre-trained Audio-Language Models for fine-tuning using parameter-efficient methods.
\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/arch.pdf}
    \caption{Proposed architecture of Audio-Language Model fine-tuning for music mixing advice generation.}
    \label{fig:architecture}
\end{figure*}
The model will process anchor track and other track stems with text prompts instructing it to provide gain-balancing advice. 
We will focus on a single anchor track approach and experiment with the number of flawed tracks in the mix: scenarios with no flawed tracks (balanced mix), one flawed track requiring adjustment, and multiple flawed tracks (2 or more) requiring simultaneous correction.
We will use Low-Rank Adaptation (LoRA) \cite{Hu_Shen_Wallis_Allen-Zhu_Li_Wang_Wang_Chen_2021} and QLoRA \cite{Dettmers_2023_QLoRA} for parameter-efficient fine-tuning. 
We will conduct studies to determine which model components to adapt.

\subsection*{Data Augmentation and Cross-Sample Training}
To improve generalization, we will implement cross-sample training strategies.
We will explore creating hybrid training examples by combining stems from different songs while maintaining musical coherence. 
This approach may help the model learn generalizable mixing principles rather than memorizing specific song characteristics.

% \subsection*{Architecture Experiments}
% We will conduct systematic experiments to optimize the model architecture and training approach.
% We will evaluate different anchor selection strategies and their impact on model performance across various musical contexts and genres.
