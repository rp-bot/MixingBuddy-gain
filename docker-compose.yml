version: "3.8"

services:
  # Development environment
  dev:
    build:
      context: .
      target: development
    ports:
      - "8888:8888" # Jupyter Lab
      - "6006:6006" # TensorBoard
    volumes:
      - .:/app
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./logs:/app/logs
      - ./cache:/app/cache
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - WANDB_API_KEY=${WANDB_API_KEY}
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Training service
  training:
    build:
      context: .
      target: training
    volumes:
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./logs:/app/logs
      - ./cache:/app/cache
      - ./configs:/app/configs
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - WANDB_API_KEY=${WANDB_API_KEY}
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
      - HF_TOKEN=${HF_TOKEN}
    command: python scripts/train.py
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Inference service
  inference:
    build:
      context: .
      target: inference
    ports:
      - "8000:8000"
    volumes:
      - ./outputs:/app/outputs
      - ./data/processed:/app/data/processed
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=/app/outputs/checkpoints/final_model
    command: python scripts/inference.py
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # MLflow tracking server
  mlflow:
    image: python:3.9-slim
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlruns/mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlruns
    command: >
      sh -c "pip install mlflow psycopg2-binary &&
             mlflow server --backend-store-uri sqlite:///mlruns/mlflow.db 
             --default-artifact-root /mlruns --host 0.0.0.0 --port 5000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Jupyter Lab for data exploration
  jupyter:
    build:
      context: .
      target: development
    ports:
      - "8889:8888"
    volumes:
      - .:/app
      - ./data:/app/data
      - ./notebooks:/app/notebooks
    environment:
      - JUPYTER_ENABLE_LAB=yes
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''

  # DVC remote storage (local)
  dvc-storage:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./dvc-storage:/usr/share/nginx/html
    command: >
      sh -c "mkdir -p /usr/share/nginx/html &&
             echo 'server { listen 80; location / { autoindex on; root /usr/share/nginx/html; } }' > /etc/nginx/conf.d/default.conf &&
             nginx -g 'daemon off;'"

  # Monitoring with Prometheus and Grafana
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=200h"
      - "--web.enable-lifecycle"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus

volumes:
  prometheus_data:
  grafana_data:

networks:
  default:
    name: llm-lora-network
