\section{Evaluation}
\label{sec:evaluation}

We evaluate the model configuration described in Section~\ref{sec:training-strategy} to assess its performance on the mixing advice task.
We employ a pattern-matching based evaluation approach to assess the accuracy of generated mixing advice.

The evaluation process analyzes each generated response to identify three key components: (1) the target stem that requires adjustment, (2) the direction of the required adjustment (increase, decrease, or no adjustment needed), and (3) the magnitude of the adjustment expressed as a dB range (e.g., 3--6 dB or 6--12 dB).

% \subsubsection{Accuracy Metrics}

% We evaluate model performance using four complementary accuracy metrics:
% \begin{itemize}
%     \item \textbf{Stem accuracy}: The percentage of predictions where the identified target stem matches the ground truth stem that received the gain adjustment.
%     \item \textbf{Direction accuracy}: The percentage of predictions where the identified adjustment direction (increase, decrease, or none) matches the expected direction based on the error category.
%     \item \textbf{Both correct}: The percentage of predictions where both the stem and direction are correctly identified, representing the strictest accuracy measure.
%     \item \textbf{Magnitude accuracy}: The percentage of predictions where the identified adjustment magnitude range (e.g., 3--6 dB or 6--12 dB) matches the expected range based on the error category.
% \end{itemize}

% Magnitude accuracy is only evaluated for samples where an adjustment is required (i.e., excluding the ``no error'' category), as these samples do not have an expected magnitude range.

% \subsubsection{False Positives and False Negatives}

% In addition to accuracy metrics, we analyze false positives and false negatives to understand the types of errors the model makes:

% \begin{itemize}
%     \item \textbf{Error detection}: We track false positives (flagging a problem in an error-free mix) and false negatives (missing an actual mixing error).
%     \item \textbf{Stem identification}: We track when the model selects the wrong stem or fails to detect the correct one.
%     \item \textbf{Direction}: We track when the model predicts the wrong adjustment direction or misses when a direction is needed.
% \end{itemize}

% These error type analyses provide insights into the model's failure modes and help identify whether the model tends to be overly conservative (missing errors) or overly aggressive (flagging non-existent problems), which is crucial for practical deployment in mixing workflows.

% \subsubsection{Performance Breakdowns}

% To gain deeper insights into model behavior, we analyze performance across multiple dimensions:
% \begin{itemize}
%     \item \textbf{By error category}: Performance breakdown across the five error categories (no error, quiet, very quiet, loud, very loud) to identify which types of mixing issues are most challenging.
%     \item \textbf{By target stem}: Performance breakdown across the three target stems (vocals, drums, bass) to assess whether the model has biases toward certain instruments.
%     \item \textbf{By direction type}: Performance breakdown by the required adjustment direction (increase, decrease, no error) to evaluate directional prediction capabilities.
% \end{itemize}

For each breakdown dimension, we compute both micro-averaged accuracies (overall performance) and macro-averaged accuracies (average across all classes, giving equal weight to each class regardless of sample distribution).
