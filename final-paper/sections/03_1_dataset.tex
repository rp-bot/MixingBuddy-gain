\subsection{Dataset}
\label{sec:dataset}
Our methodology leverages the MUSDB18HQ dataset~\cite{musdb18hq}, a high-quality multitrack audio dataset, as the foundation for our training data. 
We augment this dataset to generate flawed mixes for both Supervised Fine-Tuning (SFT) training and evaluation. 
The dataset comes with a default split into training and test sets of 100 and 50 tracks respectively.
The dataset provides four stems for each track: `bass', `drums', `other', and `vocals'. 

A key consideration in gain balancing is its relative nature. 
For instance, a bass stem is too loud in comparison to the other stems, not by some absolute value, but by a relative value.
To address this ambiguity and guide the model towards a specific solution, we introduce the concept of an `anchor' stem. 
The anchor stem is a reference track whose gain is assumed to be correct. 
Though, during training, we only use the anchor in the instruction as text description, not as a separate audio input.
By providing an anchor stem, we constrain the problem, allowing the model to infer the intended gain adjustment. 

The `other' stem often contains a wide variety of instruments and sounds, leading to inconsistency across different tracks. 
Therefore, for the purposes of controlled experiments, we exclude the `other' stem from being the target of gain alterations or being used as an anchor.

\subsubsection{SFT Dataset Synthesis}
\label{sec:sft_dataset}
Our SFT training data is synthetically generated by creating diverse instruction-response pairs through a two-stage synthesis process: flawed mix generation and response templating.
Figure~\ref{fig:dataset_synthesis} illustrates the complete synthesis pipeline.

\begin{figure*}[!ht]
\centering
\includegraphics[width=\textwidth]{figures/mixing-buddy-dataset}
\caption{Overview of the training and test sample synthesis pipeline. The process involves random flaw selection, ground truth label generation from MUSDB18, response template selection, and placeholder population to create synthesized responses.}
\label{fig:dataset_synthesis}
\end{figure*}

\textbf{Flawed Mix Generation.}
We begin by segmenting each track into 10-second chunks to ensure manageable audio lengths for processing.
For each chunk, we randomly select a flaw category from five possible categories: \textit{very quiet}, \textit{quiet}, \textit{no error}, \textit{loud}, and \textit{very loud}, each with equal probability (20\%).
We then randomly select a target stem from the available stems (bass, drums, or vocals).
Based on the selected flaw category, we perturb the target stem by applying a gain adjustment within predefined decibel ranges: very quiet ($-12$ to $-6$ dB), quiet ($-6$ to $-3$ dB), no error ($0$ dB), loud ($+3$ to $+6$ dB), and very loud ($+6$ to $+12$ dB).
The flawed mix is then created by summing all stems, including the modified target stem.
Each flawed mix is also augmented during training by applying a random gain adjustment within a predefined range of $-3$ to $+3$ dB and adding a DC offset and random noise (from $-30$ to $60$ dB) to the audio randomly.
This prevents the model from overfitting to the specific audio features of the flawed mixes.

\textbf{Response Synthesis.}
To generate corresponding textual responses, we employ a category-driven templating approach.
Figure~\ref{fig:response_synthesis} illustrates this process.
For each flaw category, we maintain a pool of 10 semantically equivalent response templates that vary in wording.
A response template is randomly selected from the category-specific template pool based on the injected flaw category.
Each template contains placeholders for dynamic variables such as the target stem name and suggested gain adjustment values (specified as \texttt{\{min\_gain\_db\}} and \texttt{\{max\_gain\_db\}}).
We use a range rather than a value because large language models are not accurate numerical value predictors, they are simply token predictors.
Enhancing the model's ability to predict numerical values is a future direction.
This process ensures that each response reflects the mixing flaw present in the corresponding flawed mix while maintaining linguistic diversity through 10 template variations per flaw category.
% These placeholders are automatically populated using the ground truth information: the actual target stem that received the error and the specific gain adjustment value (in dB) that was applied.
% For example, a \textit{quiet} category template might state: ``The \{target\_stem\} is a little too quiet. Increase the \{target\_stem\} level between \{min\_gain\_db\} and \{max\_gain\_db\} dB to balance the mix.''

\begin{figure}[!ht]
\centering
\includegraphics[width=\columnwidth]{figures/response-synthesis}
\caption{Response synthesis process. A flaw category is randomly selected, which determines the response template pool. The selected template is then populated with ground truth information including the target stem name and gain adjustment values.}
\label{fig:response_synthesis}
\end{figure}

\textbf{Instruction Generation.}
Each training sample includes an instruction that provides context to the model.
Similar to the response templates, instructions are generated by randomly selecting from a pool of 10 semantically equivalent instruction templates that vary in wording.
The instructions contain context about the mix i.e.the available stems and the anchor stem and a direct instruction to the model to provide gain balancing advice.

This synthesis pipeline produces a large-scale dataset of approximately 100,000 (instruction, response) pairs.
The dataset diversity stems from multiple augmentation dimensions: For each 10 second chunk, we randomly select 3 target stems (bass, drums, vocals), 2 possible anchor stems per target (selected from the remaining stems), and 5 error categories.
Figure~\ref{fig:augmentation_numbers} illustrates the augmentation strategy and resulting dataset composition.


\begin{figure}[!ht]
\centering
\includegraphics[width=\columnwidth]{figures/augmentation-numbers}
\caption{Dataset augmentation strategy showing the combination of target stems, anchor stems, and error categories that contribute to the final dataset of approximately 100,000 samples (including training and test sets).}
\label{fig:augmentation_numbers}
\end{figure}

