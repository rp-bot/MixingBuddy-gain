\subsection{Dataset}
\label{sec:dataset}
Our methodology leverages the MUSDB18HQ dataset~\cite{musdb18hq}, a high-quality multitrack audio dataset, as the foundation for our training data. 
We augment this dataset to generate flawed mixes for both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) training phases.
The dataset provides four stems for each track: `bass', `drums', `other', and `vocals'. 

A key consideration in gain balancing is its relative nature. 
For instance, a bass stem is too loud in comparison to the other stems, not by some absolute value, but by a relative value.
To address this ambiguity and guide the model towards a specific solution, we introduce the concept of an `anchor' stem. 
The anchor stem is a reference track whose gain is assumed to be correct. 
By providing an anchor stem, we constrain the problem, allowing the model to infer the intended gain adjustment. 

The `other' stem often contains a wide variety of instruments and sounds, leading to inconsistency across different tracks. 
Therefore, for the purposes of controlled experiments, we exclude the `other' stem from being the target of gain alterations or being used as an anchor.

\subsubsection{SFT Dataset Synthesis}
\label{sec:sft_dataset}
Our SFT training data is synthetically generated by creating diverse instruction-response pairs through a two-stage synthesis process: flawed mix generation and response templating.
Figure~\ref{fig:dataset_synthesis} illustrates the complete synthesis pipeline.

\begin{figure*}[!ht]
\centering
\includegraphics[width=\textwidth]{figures/mixing-buddy-dataset}
\caption{Overview of the training and test sample synthesis pipeline. The process involves random flaw selection, ground truth label generation from MUSDB18, response template selection, and placeholder population to create synthesized responses.}
\label{fig:dataset_synthesis}
\end{figure*}

\textbf{Flawed Mix Generation.}
We begin by segmenting each track into 10-second chunks to ensure manageable audio lengths for processing.
For each chunk, we randomly select a flaw category from five possible categories: \textit{no error}, \textit{quiet}, \textit{very quiet}, \textit{loud}, and \textit{very loud}, each with equal probability (20\%).
To ensure balanced representation in the final dataset, \textit{no error} samples are augmented to match the number of samples in each error category.
We then randomly select a target stem from the available stems (bass, drums, or vocals).
Based on the selected flaw category, we inject a gain error into the target stem by applying a gain adjustment within predefined decibel ranges: very quiet ($-12$ to $-6$ dB), quiet ($-6$ to $-3$ dB), loud ($+3$ to $+6$ dB), and very loud ($+6$ to $+12$ dB).
For the \textit{no error} category, we apply a small random gain adjustment between $-3$ and $+3$ dB to introduce natural variation while maintaining the overall balanced nature of the mix.
The flawed mix is then created by summing all stems, including the modified target stem.

\textbf{Response Synthesis.}
To generate corresponding textual responses, we employ a category-driven templating approach.
Figure~\ref{fig:response_synthesis} illustrates this process.
For each flaw category, we maintain a pool of 10 semantically equivalent response templates that vary in wording.
A response template is randomly selected from the category-specific template pool based on the injected flaw category.
Each template contains placeholders for dynamic variables such as the target stem name and suggested gain adjustment values (specified as \texttt{\{min\_gain\_db\}} and \texttt{\{max\_gain\_db\}}).
We use a range rather than a value because we assume the large language models are not accurate numerical value predictors, they are simply token predictors.
Enhancing the model's ability to predict numerical values is a future direction.
These placeholders are automatically populated using the ground truth information: the actual target stem that received the error and the specific gain adjustment value (in dB) that was applied.
For example, a \textit{quiet} category template might state: ``The \{target\_stem\} is a little too quiet. Increase the \{target\_stem\} level between \{min\_gain\_db\} and \{max\_gain\_db\} dB to balance the mix.''
This process ensures that each response reflects the mixing flaw present in the corresponding flawed mix while maintaining linguistic diversity through 10 template variations per flaw category.

\begin{figure}[!ht]
\centering
\includegraphics[width=\columnwidth]{figures/response-synthesis}
\caption{Response synthesis process. A flaw category is randomly selected, which determines the response template pool. The selected template is then populated with ground truth information including the target stem name and gain adjustment values.}
\label{fig:response_synthesis}
\end{figure}

\textbf{Instruction Generation.}
Each training sample includes an instruction that provides context to the model.
Instructions are generated by randomly selecting from a pool of 10 semantically equivalent instruction templates that vary in wording while maintaining the same semantic content.
Each template contains placeholders for chunk-specific information: the segment duration (\texttt{\{duration\_sec\}}), the list of available stems (\texttt{\{stems\_present\}}), and the anchor stem designation (\texttt{\{anchor\_stem\}}).
For example, an instruction template might state: ``Listen carefully to this \{duration\_sec\}s audio clip. The available stems are: \{stems\_present\}. Use \{anchor\_stem\} as your reference point and analyze the mix balance. Identify which stem needs adjustment and by how much.''
This approach ensures linguistic diversity in instructions while maintaining consistent semantic meaning across all training samples.

This synthesis pipeline produces a large-scale dataset of approximately 100,000 (instruction, response) triplets, including both training and test sets.
The dataset diversity stems from multiple augmentation dimensions: 3 target stems (bass, drums, vocals), 2 possible anchor stems per target (selected from the remaining stems), and 5 error categories.
For \textit{no error} samples, additional variation is introduced through random gain adjustments between $-3$ and $+3$ dB, ensuring balanced representation while maintaining the mix's overall balanced character.
Figure~\ref{fig:augmentation_numbers} illustrates the augmentation strategy and resulting dataset composition.
Each triplet contains a known gain imbalance (or balanced state for \textit{no error} samples) and a corresponding response that provides accurate feedback and corrective suggestions.

\begin{figure*}[!ht]
\centering
\includegraphics[width=\textwidth]{figures/augmentation-numbers}
\caption{Dataset augmentation strategy showing the combination of target stems, anchor stems, and error categories that contribute to the final dataset of approximately 100,000 samples (including training and test sets).}
\label{fig:augmentation_numbers}
\end{figure*}

