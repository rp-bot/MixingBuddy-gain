% TODO add first and last name in the correct format
% TODO add doi
@inproceedings{Perez_Gonzalez_Reiss_2013,
	title        = {A knowledge-engineered autonomous mixing system},
	author       = {P\'erez-Gonz\'alez, Enrique and Reiss, Joshua D.},
	year         = 2013,
	month        = oct,
	booktitle    = {Audio Engineering Society Convention 135}
}
% TODO add first and last name in the correct format
@article{Chourdakis_Reiss_2017,
	title        = {A Machine-Learning Approach to Application of Intelligent Artificial Reverberation},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2017,
	month        = feb,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 65,
	pages        = {56–65},
	doi          = {10.17743/jaes.2016.0069},
}

% TODO double chekc the authors
@article{waveunet,
	title        = {Automatic music signal mixing system based on one-dimensional Wave-U-Net autoencoders},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua D.},
	year         = 2022,
	journal      = {EURASIP Journal on Audio, Speech, and Music Processing},
	doi          = {10.1186/s13636-022-00266-3}
}

@article{Steinmetz_Pons_Pascual_Serra_2020,
	title        = {Automatic multitrack mixing with a differentiable mixing console of neural audio effects},
	author       = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
	year         = 2020,
	month        = oct,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2010.10291}
}

@article{Venkatesh_Moffat_Miranda_2022,
	title        = {Word Embeddings for Automatic Equalization in Audio Mixing},
	author       = {Venkatesh, Satvik and Moffat, David and Miranda, Eduardo Reck},
	year         = 2022,
	month        = nov,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 70,
	pages        = {753–763},
	doi          = {10.17743/jaes.2022.0047},
	issn         = 15494950,
	language     = {en}
}

@article{Chu_OReilly_Barnett_Pardo_2025,
	title        = {Text2FX: Harnessing CLAP Embeddings for Text-Guided Audio Effects},
	author       = {Chu, Annie and O'Reilly, Patrick and Barnett, Julia and Pardo, Bryan},
	year         = 2025,
	month        = feb,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2409.18847}
}

@misc{semantic-mixing,
	title        = {A Semantic Approach To Autonomous Mixing},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2016,
	language     = {en}
}

@article{Doh_Koo_Martinez-Ramirez_Liao_Nam_Mitsufuji_2025,
	title        = {Can Large Language Models Predict Audio Effects Parameters from Natural Language?},
	author       = {Doh, Seungheon and Koo, Junghyun and Martínez-Ramírez, Marco A. and Liao, Wei-Hsiang and Nam, Juhan and Mitsufuji, Yuki},
	year         = 2025,
	month        = jul,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2505.20770}
}

@article{Melechovsky_Mehrish_Herremans_2025,
	title        = {SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering},
	author       = {Melechovsky, Jan and Mehrish, Ambuj and Herremans, Dorien},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2508.03448}
}

@article{Clemens_Marasovic_2025,
	title        = {MixAssist: An Audio-Language Dataset for Co-Creative {AI} Assistance in Music Mixing},
	author       = {Michael Paul Clemens and Ana Marasovic},
	year         = 2025,
	booktitle    = {Second Conference on Language Modeling}
}

@article{Rubenstein_Asawaroengchai_Nguyen_Bapna_Borsos_Quitry_Chen_Badawy_Han_Kharitonov_etal_2023,
	title        = {AudioPaLM: A Large Language Model That Can Speak and Listen},
	author       = {Rubenstein, Paul K. and Asawaroengchai, Chulayuth and Nguyen, Duc Dung and et al.},
	year         = 2023,
	month        = jun,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2306.12925},	
}

@article{Du_Wang_Chen_Chu_Gao_Li_Hu_Zhou_Xu_Ma_etal_2024,
	title        = {LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT},
	author       = {Du, Zhihao and Wang, Jiaming and Chen, Qian and Chu, Yunfei and Gao, Zhifu and et al.},
	year         = 2024,
	month        = jul,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2310.04673}
}

@article{Zhang_Li_Zhang_Zhan_Wang_Zhou_Qiu_2023,
	title        = {SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities},
	author       = {Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
	year         = 2023,
	month        = may,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2305.11000}
}

@article{Liu_Hussain_Wu_Sun_Shan_2024,
	title        = {M$^{2}$UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models},
	author       = {Liu, Shansong and Hussain, Atin Sakkeer and Wu, Qilong and Sun, Chenshuo and Shan, Ying},
	year         = 2024,
	month        = dec,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2311.11255}
}

@article{Gong_Luo_Liu_Karlinsky_Glass_2024,
	title        = {Listen, Think, and Understand},
	author       = {Gong, Yuan and Luo, Hongyin and Liu, Alexander H. and Karlinsky, Leonid and Glass, James},
	year         = 2024,
	month        = feb,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2305.10790}
}