% TODO add first and last name in the correct format
% TODO add doi
@inproceedings{Perez_Gonzalez_Reiss_2013,
	title        = {A knowledge-engineered autonomous mixing system},
	author       = {P\'erez-Gonz\'alez, Enrique and Reiss, Joshua D.},
	year         = 2013,
	month        = oct,
	booktitle    = {Audio Engineering Society Convention 135},
	url          = {http://www.aes.org/e-lib/browse.cfm?elib=16953}
}
% TODO add first and last name in the correct format
@article{Chourdakis_Reiss_2017,
	title        = {A Machine-Learning Approach to Application of Intelligent Artificial Reverberation},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2017,
	month        = feb,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 65,
	number       = {1/2},
	pages        = {56–65},
	doi          = {10.17743/jaes.2016.0069},
}

% TODO double chekc the authors
@article{waveunet,
	title        = {Automatic music signal mixing system based on one-dimensional Wave-U-Net autoencoders},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2022,
	journal      = {EURASIP Journal on Audio, Speech, and Music Processing},
	doi          = {10.1186/s13636-022-00266-3},
	url          = {https://www.researchgate.net/publication/366902955_Automatic_music_signal_mixing_system_based_on_one-dimensional_Wave-U-Net_autoencoders}
}

@article{Steinmetz_Pons_Pascual_Serra_2020,
	title        = {Automatic multitrack mixing with a differentiable mixing console of neural audio effects},
	author       = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
	year         = 2020,
	month        = oct,
	publisher    = {arXiv},
	number       = {arXiv:2010.10291},
	doi          = {10.48550/arXiv.2010.10291},
	url          = {http://arxiv.org/abs/2010.10291},
	note         = {arXiv:2010.10291 [eess]}
}

@article{Venkatesh_Moffat_Miranda_2022,
	title        = {Word Embeddings for Automatic Equalization in Audio Mixing},
	author       = {Venkatesh, Satvik and Moffat, David and Miranda, Eduardo Reck},
	year         = 2022,
	month        = nov,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 70,
	number       = 9,
	pages        = {753–763},
	doi          = {10.17743/jaes.2022.0047},
	issn         = 15494950,
	language     = {en}
}

@article{Chu_OReilly_Barnett_Pardo_2025,
	title        = {Text2FX: Harnessing CLAP Embeddings for Text-Guided Audio Effects},
	author       = {Chu, Annie and O'Reilly, Patrick and Barnett, Julia and Pardo, Bryan},
	year         = 2025,
	month        = feb,
	publisher    = {arXiv},
	number       = {arXiv:2409.18847},
	doi          = {10.48550/arXiv.2409.18847},
	url          = {http://arxiv.org/abs/2409.18847},
	note         = {arXiv:2409.18847 [eess]}
}

@misc{semantic-mixing,
	title        = {A Semantic Approach To Autonomous Mixing},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2016,
	url          = {https://www.researchgate.net/publication/273574043_A_Semantic_Approach_To_Autonomous_Mixing},
	abstractnote = {PDF | In this work, we give an overview of current automatic mixing approaches, and note the absence of using high-level, semantic knowledge to inform... | Find, read and cite all the research you need on ResearchGate},
	language     = {en}
}

@article{Doh_Koo_Martinez-Ramirez_Liao_Nam_Mitsufuji_2025,
	title        = {Can Large Language Models Predict Audio Effects Parameters from Natural Language?},
	author       = {Doh, Seungheon and Koo, Junghyun and Martínez-Ramírez, Marco A. and Liao, Wei-Hsiang and Nam, Juhan and Mitsufuji, Yuki},
	year         = 2025,
	month        = jul,
	publisher    = {arXiv},
	number       = {arXiv:2505.20770},
	doi          = {10.48550/arXiv.2505.20770},
	url          = {http://arxiv.org/abs/2505.20770},
	note         = {arXiv:2505.20770 [cs]}
}

@article{Melechovsky_Mehrish_Herremans_2025,
	title        = {SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering},
	author       = {Melechovsky, Jan and Mehrish, Ambuj and Herremans, Dorien},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	number       = {arXiv:2508.03448},
	doi          = {10.48550/arXiv.2508.03448},
	url          = {http://arxiv.org/abs/2508.03448},
	note         = {arXiv:2508.03448 [eess]}
}

@article{Clemens_Marasovic_2025,
	title        = {MixAssist: An Audio-Language Dataset for Co-Creative {AI} Assistance in Music Mixing},
	author       = {Michael Paul Clemens and Ana Marasovic},
	year         = 2025,
	booktitle    = {Second Conference on Language Modeling},
	url          = {https://openreview.net/forum?id=5mICyyD4OF}
}

@article{Rubenstein_Asawaroengchai_Nguyen_Bapna_Borsos_Quitry_Chen_Badawy_Han_Kharitonov_etal_2023,
	title        = {AudioPaLM: A Large Language Model That Can Speak and Listen},
	author       = {Rubenstein, Paul K. and Asawaroengchai, Chulayuth and Nguyen, Duc Dung and Bapna, Ankur and Borsos, Zalán and Quitry, Félix de Chaumont and Chen, Peter and Badawy, Dalia El and Han, Wei and Kharitonov, Eugene and Muckenhirn, Hannah and Padfield, Dirk and Qin, James and Rozenberg, Danny and Sainath, Tara and Schalkwyk, Johan and Sharifi, Matt and Ramanovich, Michelle Tadmor and Tagliasacchi, Marco and Tudor, Alexandru and Velimirović, Mihajlo and Vincent, Damien and Yu, Jiahui and Wang, Yongqiang and Zayats, Vicky and Zeghidour, Neil and Zhang, Yu and Zhang, Zhishuai and Zilka, Lukas and Frank, Christian},
	year         = 2023,
	month        = jun,
	publisher    = {arXiv},
	number       = {arXiv:2306.12925},
	doi          = {10.48550/arXiv.2306.12925},
	url          = {http://arxiv.org/abs/2306.12925},
	note         = {arXiv:2306.12925 [cs]}
}

@article{Du_Wang_Chen_Chu_Gao_Li_Hu_Zhou_Xu_Ma_etal_2024,
	title        = {LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT},
	author       = {Du, Zhihao and Wang, Jiaming and Chen, Qian and Chu, Yunfei and Gao, Zhifu and Li, Zerui and Hu, Kai and Zhou, Xiaohuan and Xu, Jin and Ma, Ziyang and Wang, Wen and Zheng, Siqi and Zhou, Chang and Yan, Zhijie and Zhang, Shiliang},
	year         = 2024,
	month        = jul,
	publisher    = {arXiv},
	number       = {arXiv:2310.04673},
	doi          = {10.48550/arXiv.2310.04673},
	url          = {http://arxiv.org/abs/2310.04673},
	note         = {arXiv:2310.04673 [cs]}
}

@article{Zhang_Li_Zhang_Zhan_Wang_Zhou_Qiu_2023,
	title        = {SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities},
	author       = {Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
	year         = 2023,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2305.11000},
	doi          = {10.48550/arXiv.2305.11000},
	url          = {http://arxiv.org/abs/2305.11000},
	note         = {arXiv:2305.11000 [cs]}
}

@article{Liu_Hussain_Wu_Sun_Shan_2024,
	title        = {M$^{2}$UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models},
	author       = {Liu, Shansong and Hussain, Atin Sakkeer and Wu, Qilong and Sun, Chenshuo and Shan, Ying},
	year         = 2024,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2311.11255},
	doi          = {10.48550/arXiv.2311.11255},
	url          = {http://arxiv.org/abs/2311.11255},
	note         = {arXiv:2311.11255 [cs]}
}

@article{Gong_Luo_Liu_Karlinsky_Glass_2024,
	title        = {Listen, Think, and Understand},
	author       = {Gong, Yuan and Luo, Hongyin and Liu, Alexander H. and Karlinsky, Leonid and Glass, James},
	year         = 2024,
	month        = feb,
	publisher    = {arXiv},
	number       = {arXiv:2305.10790},
	doi          = {10.48550/arXiv.2305.10790},
	url          = {http://arxiv.org/abs/2305.10790},
	note         = {arXiv:2305.10790 [eess]}
}