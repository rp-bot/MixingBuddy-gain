# @package _global_

# Training config - Resume from checkpoint 600 of Experiment 19
# Experiment 20: Continue training MERT top3 + LoRA adapters from checkpoint 600
# Goal: Train to ~1000 steps to achieve better convergence before DPO

defaults:
  - data: 07_dpo_data
  - model: qwen2_7b_mert_top3_musdb_expanded_lora
  - training: 13_dpo_training
  - experiment_tracking: wandb
  - experiment_naming: experiment_naming
  - _self_

# Environment settings
env:
  seed: 42
  project_name: "automatic-mixing-milestone-0"
  output_dir: "outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}"

# Experiment tracking settings
experiment_tracking:
  use_wandb: false
  use_mlflow: false

hydra:
  run:
    dir: ${env.output_dir}

training:
  resume:
    enabled: true
    weight_only: true  # Full resume to continue training state
    checkpoint_path: "outputs/checkpoints/mixing_buddy_milestone_0/qlora-qwen2-7b-mert-top3-musdb-expanded-lora-r16a32-musdb/checkpoint-600"