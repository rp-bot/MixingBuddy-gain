# @package model

# Model configuration - NO LoRA adapters, ONLY train audio projection
# This is the most constrained setup to force audio usage
model_name: "Qwen/Qwen2-7B-Instruct"
config_name: "qwen2_7b_projection_only"
use_qlora: true

# LoRA configuration with NO target modules
# The LLM is completely frozen
lora:
  r: 16
  lora_alpha: 32
  target_modules: [] # Empty list = no LoRA adapters!
  lora_dropout: 0.1
  bias: "none"
  task_type: "CAUSAL_LM"

# QLoRA quantization configuration
quantization:
  load_in_4bit: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_use_double_quant: true

# Audio encoder configuration
encoder:
  model_name: "facebook/encodec_32khz"
  freeze: true
  device: cuda # Will be set automatically based on LLM device

# Audio projection configuration
# Since projection is the ONLY trainable part, we might want to increase capacity
projection:
  type: "mlp"
  hidden_dims: [512, 1024, 2048, 2048, 1024] # Deeper network
  activation: "relu"
  dropout: 0.1
  use_layer_norm: true
  use_residual: false
  # Auxiliary loss is CRITICAL here since it's the only training signal
  use_auxiliary_loss: true
  auxiliary_loss_weight: 0.05 # Increased weight since it's more important

