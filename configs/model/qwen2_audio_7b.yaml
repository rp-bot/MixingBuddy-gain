# @package model

# Qwen2-Audio-7B-Instruct configuration
_target_: transformers.AutoModelForCausalLM.from_pretrained

pretrained_model_name_or_path: "Qwen/Qwen2-Audio-7B-Instruct"
trust_remote_code: true
torch_dtype: "auto"
device_map: "auto"

# LoRA configuration for Qwen2-Audio
lora:
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  bias: "none"
  task_type: "CAUSAL_LM"
  inference_mode: false

# Quantization (optional)
quantization:
  load_in_8bit: false
  load_in_4bit: false
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_type: "nf4"

# Audio processing configuration
audio:
  sample_rate: 44100
  max_audio_length: 30.0 # seconds
  audio_channels: 1 # mono
  audio_format: "wav"

# Multi-modal configuration
multimodal:
  audio_encoder: "qwen2_audio"
  text_encoder: "qwen2"
  fusion_method: "cross_attention"
  audio_tokens_per_second: 50
