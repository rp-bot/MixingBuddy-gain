# @package model

# Test model configuration - minimal LoRA parameters for quick testing
pretrained_model_name_or_path: "Qwen/Qwen2-Audio-7B-Instruct"
trust_remote_code: true
torch_dtype: "auto"
device_map: "auto"

# Quantization for memory optimization - REQUIRED!
quantization:
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_type: "nf4"

# LoRA configuration - minimal for testing
lora:
  r: 8 # Smaller rank for testing
  lora_alpha: 16 # 2x rank
  lora_dropout: 0.1
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  bias: "none"
  task_type: "CAUSAL_LM"
  inference_mode: false

# Training configuration
training:
  use_cache: false
  gradient_checkpointing: true # Test re-enabling gradient checkpointing

# Model configuration
model_config:
  use_cache: false
  torch_dtype: "auto"
