# @package model

# Model configuration for multi-label stem classification
# Architecture: Audio Encoder -> (Optional Projection) -> Classification Head
# Multi-label classification: 3 stems Ã— 5 categories = 15 classes

# Name used by run-name utilities / logging
model_name: "stem_gain"

# Number of classes:
#   3 stems: vocals, drums, bass
#   5 categories per stem: very_quiet, quiet, balanced, loud, very_loud
#   Total: 15 classes (vocals_very_quiet, vocals_quiet, ..., bass_very_loud)
num_classes: 15

# Feature pooling method: "mean", "max", or "attention"
pooling_method: "mean"

# Audio encoder configuration - MERT
encoder:
  model_name: "m-a-p/MERT-v1-330M"
  freeze: true
  device: cuda
  input_sample_rate: 24000  # Match dataset sample rate (MERT's native rate is 24kHz)
  freeze_layer_weights: false

# Optional projection layer
# Set to null to skip projection (encoder -> heads directly)
# Or configure a projection layer
projection:
  type: "linear"
  output_dim: 256  # Bottleneck: 1024 -> 256 to strip song identity info
  dropout: 0.2     # Regularize the projection features

# Task head configuration (multi-label classification)
# Configurable depth and architecture
head:
  hidden_dims: [256, 128]  # Increased from [128]: 256 -> 256 -> 128 -> output (2 hidden layers for better capacity)
  dropout: 0.3             # High dropout to force generalization
  activation: "relu"        # Options: "relu", "gelu", "tanh"
# Default (if head is null): [512] (2-layer: 1024 -> 512 -> output)
