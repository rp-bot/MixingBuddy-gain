# @package model

# Model configuration for Qwen2 7B with Transformer projection
model_name: "Qwen/Qwen2-7B-Instruct"
config_name: "qwen2_7b_transformer_projection"
use_qlora: true

# LoRA configuration
lora:
  r: 8
  lora_alpha: 16
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  lora_dropout: 0.1
  bias: "none"
  task_type: "CAUSAL_LM"

# QLoRA quantization configuration
quantization:
  load_in_4bit: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_use_double_quant: true

# Audio encoder configuration
encoder:
  model_name: "facebook/encodec_32khz"
  freeze: true
  device: cuda # Will be set automatically based on LLM device

# Audio projection configuration - Transformer
projection:
  type: "transformer"
  num_layers: 3
  num_heads: 8
  feedforward_dim: 2048 # 4 * 512 (input_dim)
  dropout: 0.1
  use_layer_norm: true
  max_seq_len: 2048
