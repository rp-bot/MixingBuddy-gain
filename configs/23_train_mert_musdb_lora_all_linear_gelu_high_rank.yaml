# @package _global_

# Training config with MERT encoder, augmented multi-anchor data, and LoRA on all linear layers
# Experiment 23: MERT + multi-anchor MUSDB data (augmented no-error class) + LoRA all linear layers

defaults:
  - data: 08_musdb_expanded_augmented_variations
  - model: qwen2_7b_mert_musdb_expanded_lora_all_linear
  - training: 11_training
  - experiment_tracking: wandb
  - experiment_naming: experiment_naming
  - _self_

model:
  config_name: "qwen2_7b_mert_musdb_expanded_lora_all_linear_gelu"
  projection:
    activation: "gelu"
    dropout: 0.1

  lora:
    lora_dropout: 0.3
    r: 32
    lora_alpha: 64

# Environment settings
env:
  seed: 42
  project_name: "automatic-mixing-milestone-0"
  output_dir: "outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}"

# Experiment tracking settings
experiment_tracking:
  use_wandb: false
  use_mlflow: false

hydra:
  run:
    dir: ${env.output_dir}

training:
  resume:
    enabled: true
    weight_only: false  # Set to true for weight-only resume (loads weights but starts fresh training)
    # checkpoint_path: "outputs/checkpoints/mixing_buddy_milestone_0/qlora-qwen2-7b-mert-musdb-expanded-lora-all-linear-r16a32-musdb/checkpoint-1600"
    checkpoint_path: "outputs/checkpoints/mixing_buddy_milestone_0/qlora-qwen2-7b-mert-musdb-expanded-lora-all-linear-gelu-r32a64-musdb/checkpoint-1600"

