# @package training

# Training arguments
training_args:
  output_dir: "./outputs"
  num_train_epochs: 3
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 4
  lr_scheduler_type: "linear"
  learning_rate: 2e-4
  weight_decay: 0.01
  warmup_ratio: 0.1
  logging_steps: 10
  eval_steps: 100
  save_steps: 100
  save_total_limit: 3
  save_strategy: "steps"
  eval_strategy: "steps"
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  report_to: "none" # or "mlflow" or "none" for no tracking
  run_name: null # Will be set automatically if null

# Mixed precision training
mixed_precision:
  enabled: true
  dtype: "bf16" # or "fp16"

# Early stopping
early_stopping:
  enabled: true
  patience: 3
