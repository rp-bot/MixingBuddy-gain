% ================================================
% AI FOUNDATIONS
% ================================================
@inproceedings{Bougueng_Tchemeube_Ens_Plut_Pasquier_Safi_Grabit_Rolland_2023,
	title        = {Evaluating Human-AI Interaction via Usability, User Experience and Acceptance Measures for MMM-C: A Creative AI System for Music Composition},
	author       = {Bougueng Tchemeube, Renaud and Ens, Jeffrey and Plut, Cale and Pasquier, Philippe and Safi, Maryam and Grabit, Yvan and Rolland, Jean-Baptiste},
	year         = 2023,
	month        = aug,
	booktitle    = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	address      = {Macau, SAR China},
	pages        = {5769–5778},
	doi          = {10.24963/ijcai.2023/640},
	isbn         = {978-1-956792-03-4},
	url          = {https://www.ijcai.org/proceedings/2023/640},
	language     = {en}
}
@article{Clemens_Marasovic_2025,
	title        = {MixAssist: An Audio-Language Dataset for Co-Creative {AI} Assistance in Music Mixing},
	author       = {Michael Paul Clemens and Ana Marasovic},
	year         = 2025,
	booktitle    = {Second Conference on Language Modeling},
	url          = {https://openreview.net/forum?id=5mICyyD4OF}
}
% ================================================
% CO-CREATIVE AI
% ================================================
@inproceedings{Louie_Coenen_Huang_Terry_Cai_2020b,
	title        = {Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models},
	author       = {Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry, Michael and Cai, Carrie J.},
	year         = 2020,
	month        = apr,
	booktitle    = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
	publisher    = {ACM},
	address      = {Honolulu HI USA},
	pages        = {1–13},
	doi          = {10.1145/3313831.3376739},
	isbn         = {978-1-4503-6708-0},
	url          = {https://dl.acm.org/doi/10.1145/3313831.3376739},
	language     = {en}
}
@misc{Tsiros_Palladini_2020,
	title        = {Towards a Human-Centric Design Framework for AI Assisted Music Production},
	author       = {Tsiros, Augoustinos and Palladini, Alessandro},
	year         = 2020,
	month        = jun,
	journal      = {Proceedings of the International Conference on New Interfaces for Musical Expression},
	publisher    = {Zenodo},
	pages        = {399--404},
	doi          = {10.5281/zenodo.4813436},
	url          = {https://zenodo.org/records/4813436}
}
@inproceedings{Vanka_Rolland_Fazekas_2025,
	title        = {Demonstrating Diff-MSTC: A Controllable and Context-Aware AI System for Multitrack Mixing in Digital Audio Workstation Cubase},
	author       = {Vanka, Soumya Sai and Rolland, Jean-Baptiste and Fazekas, György},
	year         = 2025,
	month        = apr,
	booktitle    = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
	publisher    = {ACM},
	address      = {Yokohama Japan},
	pages        = {1–5},
	doi          = {10.1145/3706599.3721167},
	isbn         = {979-8-4007-1395-8},
	url          = {https://dl.acm.org/doi/10.1145/3706599.3721167},
	language     = {en}
}
@article{Vanka_Safi_Rolland_Fazekas_2023,
	title        = {Adoption of AI Technology in the Music Mixing Workflow: An Investigation},
	author       = {Vanka, Soumya Sai and Safi, Maryam and Rolland, Jean-Baptiste and Fazekas, George},
	year         = 2023,
	month        = sep,
	publisher    = {arXiv},
	number       = {arXiv:2304.03407},
	doi          = {10.48550/arXiv.2304.03407},
	url          = {http://arxiv.org/abs/2304.03407},
	note         = {arXiv:2304.03407 [cs]}
}
% ================================================
% DATASETS
% ================================================
@misc{Bittner_Salamon_Tierney_Mauch_Cannam_Bello_2014,
	title        = {MedleyDB Audio: A Dataset of Multitrack Audio for Music Research},
	author       = {Bittner, Rachel and Salamon, Justin and Tierney, Mike and Mauch, Matthias and Cannam, Chris and Bello, Juan Pablo},
	year         = 2014,
	month        = oct,
	publisher    = {Zenodo},
	url          = {https://zenodo.org/records/1649325},
	language     = {eng}
}
@inproceedings{Man_Reiss_2017,
	title        = {The Mix Evaluation Dataset},
	author       = {Man, Brecht De and Reiss, Joshua D},
	year         = 2017,
	booktitle    = {Proceedings of the 20th International Conference on Digital Audio Effects (DAFx-17), Edinburgh, UK, September 5–9, 2017},
	pages        = {447–453},
	url          = {http://c4dm.eecs.qmul.ac.uk/multitrack/MixEvaluation/},
	language     = {en}
}
@misc{Rafii_Liutkus_Stoter_Mimilakis_Bittner_2019,
	title        = {MUSDB18-HQ - an uncompressed version of MUSDB18},
	author       = {Rafii, Zafar and Liutkus, Antoine and Stöter, Fabian-Robert and Mimilakis, Stylianos Ioannis and Bittner, Rachel},
	year         = 2019,
	month        = aug,
	doi          = {10.5281/zenodo.3338373},
	url          = {https://doi.org/10.5281/zenodo.3338373}
}
% ================================================
% EVOLUTION
% ================================================
@inproceedings{kong2018attention,
	title        = {Attention-based deep multiple instance learning for weakly supervised audio tagging},
	author       = {Kong, Qiuqiang and Xu, Yong and Plumbley, Mark D},
	year         = 2018,
	booktitle    = {2018 26th European Signal Processing Conference (EUSIPCO)},
	pages        = {111--115},
	organization = {IEEE}
}
@article{Borsos_Marinier_Vincent_Kharitonov_Pietquin_Sharifi_Roblek_Teboul_Grangier_Tagliasacchi_etal_2023,
	title        = {AudioLM: A Language Modeling Approach to Audio Generation},
	author       = {Borsos, Zalán and Marinier, Raphaël and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
	year         = 2023,
	journal      = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	volume       = 31,
	pages        = {2523–2533},
	doi          = {10.1109/TASLP.2023.3288409},
	issn         = {2329-9304}
}
@inproceedings{Elizalde_Deshmukh_Ismail_Wang_2023,
	title        = {CLAP Learning Audio Concepts from Natural Language Supervision},
	author       = {Elizalde, Benjamin and Deshmukh, Soham and Ismail, Mahmoud Al and Wang, Huaming},
	year         = 2023,
	month        = jun,
	booktitle    = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {1–5},
	doi          = {10.1109/ICASSP49357.2023.10095889},
	issn         = {2379-190X},
	url          = {https://ieeexplore.ieee.org/document/10095889}
}
@article{Koepke_Oncescu_Henriques_Akata_Albanie_2023,
	title        = {Audio Retrieval With Natural Language Queries: A Benchmark Study},
	author       = {Koepke, A. Sophia and Oncescu, Andreea-Maria and Henriques, João F. and Akata, Zeynep and Albanie, Samuel},
	year         = 2023,
	journal      = {IEEE Transactions on Multimedia},
	volume       = 25,
	pages        = {2675–2685},
	doi          = {10.1109/TMM.2022.3149712},
	issn         = {1941-0077}
}
@article{Liu_Yuan_Liu_Mei_Kong_Tian_Wang_Wang_Wang_Plumbley_2024,
	title        = {AudioLDM 2: Learning Holistic Audio Generation With Self-Supervised Pretraining},
	author       = {Liu, Haohe and Yuan, Yi and Liu, Xubo and Mei, Xinhao and Kong, Qiuqiang and Tian, Qiao and Wang, Yuping and Wang, Wenwu and Wang, Yuxuan and Plumbley, Mark D.},
	year         = 2024,
	journal      = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	volume       = 32,
	pages        = {2871–2883},
	doi          = {10.1109/TASLP.2024.3399607},
	issn         = {2329-9304}
}
@inproceedings{Radford_Kim_Xu_Brockman_Mcleavey_Sutskever_2023,
	title        = {Robust Speech Recognition via Large-Scale Weak Supervision},
	author       = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and Mcleavey, Christine and Sutskever, Ilya},
	year         = 2023,
	month        = jul,
	booktitle    = {Proceedings of the 40th International Conference on Machine Learning},
	publisher    = {PMLR},
	pages        = {28492–28518},
	issn         = {2640-3498},
	url          = {https://proceedings.mlr.press/v202/radford23a.html},
	language     = {en}
}
@inproceedings{Wu_Nieto_Bello_Salamon_2023,
	title        = {Audio-Text Models Do Not Yet Leverage Natural Language},
	author       = {Wu, Ho-Hsiang and Nieto, Oriol and Bello, Juan Pablo and Salamon, Justin},
	year         = 2023,
	month        = jun,
	booktitle    = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {1–5},
	doi          = {10.1109/ICASSP49357.2023.10097117},
	issn         = {2379-190X},
	url          = {https://ieeexplore.ieee.org/document/10097117}
}
@article{Xue_Deng_Gao_Li_2024,
	title        = {Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation},
	author       = {Xue, Jinlong and Deng, Yayue and Gao, Yingming and Li, Ya},
	year         = 2024,
	journal      = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	volume       = 32,
	pages        = {4700–4712},
	doi          = {10.1109/TASLP.2024.3485485},
	issn         = {2329-9304}
}
% ================================================
% LARGE LANGUAGE MODELS
% ================================================
@article{zhao2023survey,
	title        = {A survey of large language models},
	author       = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.18223}
}
@inproceedings{lu2022unified,
	title        = {Unified-io: A unified model for vision, language, and audio},
	author       = {Lu, Jiasen and Clark, Christopher and Zellers, Rowan and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision},
	pages        = {525--542},
	organization = {Springer}
}
@article{borsos2022audiolm,
	title        = {Audiolm: a language modeling approach to audio generation},
	author       = {Borsos, Zal{\'a}n and Frank, Raphael and Zeghidour, Neil and Chan, Yanqi and Jansen, Aren and Henderson, Peter and Tagliasacchi, Marco and Sharifi, Mohammad},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2209.03143}
}
@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}
@article{Chu_Xu_Zhou_Yang_Zhang_Yan_Zhou_Zhou_2023,
	title        = {Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models},
	author       = {Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
	year         = 2023,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2311.07919},
	doi          = {10.48550/arXiv.2311.07919},
	url          = {http://arxiv.org/abs/2311.07919},
	note         = {arXiv:2311.07919 [eess]}
}
@article{Elizalde_Deshmukh_Wang_2024,
	title        = {Natural Language Supervision for General-Purpose Audio Representations},
	author       = {Elizalde, Benjamin and Deshmukh, Soham and Wang, Huaming},
	year         = 2024,
	month        = feb,
	publisher    = {arXiv},
	number       = {arXiv:2309.05767},
	doi          = {10.48550/arXiv.2309.05767},
	url          = {http://arxiv.org/abs/2309.05767},
	note         = {arXiv:2309.05767 [cs]}
}
@article{Lyu_Wu_Wang_Huang_Liu_Du_Shi_Tu_2023,
	title        = {Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration},
	author       = {Lyu, Chenyang and Wu, Minghao and Wang, Longyue and Huang, Xinting and Liu, Bingshuai and Du, Zefeng and Shi, Shuming and Tu, Zhaopeng},
	year         = 2023,
	month        = jun,
	publisher    = {arXiv},
	number       = {arXiv:2306.09093},
	doi          = {10.48550/arXiv.2306.09093},
	url          = {http://arxiv.org/abs/2306.09093},
	note         = {arXiv:2306.09093 [cs]}
}
@article{Su_Lan_Li_Xu_Wang_Cai_2023,
	title        = {PandaGPT: One Model To Instruction-Follow Them All},
	author       = {Su, Yixuan and Lan, Tian and Li, Huayang and Xu, Jialu and Wang, Yan and Cai, Deng},
	year         = 2023,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2305.16355},
	doi          = {10.48550/arXiv.2305.16355},
	url          = {http://arxiv.org/abs/2305.16355},
	note         = {arXiv:2305.16355 [cs]}
}
@article{Tang_Yu_Sun_Chen_Tan_Li_Lu_Ma_Zhang_2024,
	title        = {SALMONN: Towards Generic Hearing Abilities for Large Language Models},
	author       = {Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
	year         = 2024,
	month        = apr,
	publisher    = {arXiv},
	number       = {arXiv:2310.13289},
	doi          = {10.48550/arXiv.2310.13289},
	url          = {http://arxiv.org/abs/2310.13289},
	note         = {arXiv:2310.13289 [cs]}
}
@article{Vyas_Shi_Le_Tjandra_Wu_Guo_Zhang_Zhang_Adkins_Ngan_eta_2023,
	title        = {Audiobox: Unified Audio Generation with Natural Language Prompts},
	author       = {Vyas, Apoorv and Shi, Bowen and Le, Matthew and Tjandra, Andros and Wu, Yi-Chiao and Guo, Baishan and Zhang, Jiemin and Zhang, Xinyue and Adkins, Robert and Ngan, William and Wang, Jeff and Cruz, Ivan and Akula, Bapi and Akinyemi, Akinniyi and Ellis, Brian and Moritz, Rashel and Yungster, Yael and Rakotoarison, Alice and Tan, Liang and Summers, Chris and Wood, Carleigh and Lane, Joshua and Williamson, Mary and Hsu, Wei-Ning},
	year         = 2023,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2312.15821},
	doi          = {10.48550/arXiv.2312.15821},
	url          = {http://arxiv.org/abs/2312.15821},
	note         = {arXiv:2312.15821 [cs]}
}
@misc{Wu_Fei_Qu_Ji_Chua_2024,
	title        = {{NE}xT-{GPT}: Any-to-Any Multimodal {LLM}},
	author       = {Shengqiong Wu and Hao Fei and Leigang Qu and Wei Ji and Tat-Seng Chua},
	year         = 2024,
	url          = {https://openreview.net/forum?id=0A5o6dCKeK}
}
@article{Agostinelli_Denk_Borsos_Engel_Verzetti_Caillon_Huang_Jansen_Roberts_Tagliasacchi_etal_2023,
	title        = {MusicLM: Generating Music From Text},
	author       = {Agostinelli, Andrea and Denk, Timo I. and Borsos, Zalán and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and Sharifi, Matt and Zeghidour, Neil and Frank, Christian},
	year         = 2023,
	month        = jan,
	publisher    = {arXiv},
	number       = {arXiv:2301.11325},
	doi          = {10.48550/arXiv.2301.11325},
	url          = {http://arxiv.org/abs/2301.11325},
	note         = {arXiv:2301.11325 [cs]}
}
@inproceedings{Copet_Kreuk_Gat_Remez_Kant_Synnaeve_Adi_Défossez,
	title        = {Simple and controllable music generation},
	author       = {Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D\'{e}fossez, Alexandre},
	year         = 2023,
	booktitle    = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
	location     = {New Orleans, LA, USA},
	publisher    = {Curran Associates Inc.},
	address      = {Red Hook, NY, USA},
	series       = {NIPS '23},
	articleno    = 2066,
	numpages     = 17
}
@article{Dhariwal_Jun_Payne_Kim_Radford_Sutskever_2020,
	title        = {Jukebox: A Generative Model for Music},
	author       = {Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
	year         = 2020,
	month        = apr,
	publisher    = {arXiv},
	number       = {arXiv:2005.00341},
	doi          = {10.48550/arXiv.2005.00341},
	url          = {http://arxiv.org/abs/2005.00341},
	note         = {arXiv:2005.00341 [eess]}
}
@article{Ding_Liu_Dong_Zhang_Qian_Huang_He_Lin_Wang_2025,
	title        = {SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition},
	author       = {Ding, Shuangrui and Liu, Zihan and Dong, Xiaoyi and Zhang, Pan and Qian, Rui and Huang, Junhao and He, Conghui and Lin, Dahua and Wang, Jiaqi},
	year         = 2025,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2402.17645},
	doi          = {10.48550/arXiv.2402.17645},
	url          = {http://arxiv.org/abs/2402.17645},
	note         = {arXiv:2402.17645 [cs]}
}
@article{Du_Wang_Chen_Chu_Gao_Li_Hu_Zhou_Xu_Ma_etal_2024,
	title        = {LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT},
	author       = {Du, Zhihao and Wang, Jiaming and Chen, Qian and Chu, Yunfei and Gao, Zhifu and Li, Zerui and Hu, Kai and Zhou, Xiaohuan and Xu, Jin and Ma, Ziyang and Wang, Wen and Zheng, Siqi and Zhou, Chang and Yan, Zhijie and Zhang, Shiliang},
	year         = 2024,
	month        = jul,
	publisher    = {arXiv},
	number       = {arXiv:2310.04673},
	doi          = {10.48550/arXiv.2310.04673},
	url          = {http://arxiv.org/abs/2310.04673},
	note         = {arXiv:2310.04673 [cs]}
}
@article{Gardner_Durand_Stoller_Bittner_2024,
	title        = {LLark: A Multimodal Instruction-Following Language Model for Music},
	author       = {Gardner, Josh and Durand, Simon and Stoller, Daniel and Bittner, Rachel M.},
	year         = 2024,
	month        = jun,
	publisher    = {arXiv},
	number       = {arXiv:2310.07160},
	doi          = {10.48550/arXiv.2310.07160},
	url          = {http://arxiv.org/abs/2310.07160},
	note         = {arXiv:2310.07160 [cs]}
}
@article{Ghosal_Majumder_Mehrish_Poria_2023,
	title        = {Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model},
	author       = {Ghosal, Deepanway and Majumder, Navonil and Mehrish, Ambuj and Poria, Soujanya},
	year         = 2023,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2304.13731},
	doi          = {10.48550/arXiv.2304.13731},
	url          = {http://arxiv.org/abs/2304.13731},
	note         = {arXiv:2304.13731 [eess]}
}
@article{Gong_Luo_Liu_Karlinsky_Glass_2024,
	title        = {Listen, Think, and Understand},
	author       = {Gong, Yuan and Luo, Hongyin and Liu, Alexander H. and Karlinsky, Leonid and Glass, James},
	year         = 2024,
	month        = feb,
	publisher    = {arXiv},
	number       = {arXiv:2305.10790},
	doi          = {10.48550/arXiv.2305.10790},
	url          = {http://arxiv.org/abs/2305.10790},
	note         = {arXiv:2305.10790 [eess]}
}
@inproceedings{Hao_Zhou_Liu_Li_Hu_Wang_Wei_2025,
	title        = {Boosting Large Language Model for Speech Synthesis: An Empirical Study},
	author       = {Hao, Hongkun and Zhou, Long and Liu, Shujie and Li, Jinyu and Hu, Shujie and Wang, Rui and Wei, Furu},
	year         = 2025,
	month        = apr,
	booktitle    = {ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {1–5},
	doi          = {10.1109/ICASSP49660.2025.10890588},
	issn         = {2379-190X},
	url          = {https://ieeexplore.ieee.org/abstract/document/10890588}
}
@article{Huang_Li_Yang_Shi_Chang_Ye_Wu_Hong_Huang_Liu_etal_2023,
	title        = {AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head},
	author       = {Huang, Rongjie and Li, Mingze and Yang, Dongchao and Shi, Jiatong and Chang, Xuankai and Ye, Zhenhui and Wu, Yuning and Hong, Zhiqing and Huang, Jiawei and Liu, Jinglin and Ren, Yi and Zhao, Zhou and Watanabe, Shinji},
	year         = 2023,
	month        = apr,
	publisher    = {arXiv},
	number       = {arXiv:2304.12995},
	doi          = {10.48550/arXiv.2304.12995},
	url          = {http://arxiv.org/abs/2304.12995},
	note         = {arXiv:2304.12995 [cs]}
}
@article{Kakouros_imko_Vainio_Suni_2023,
	title        = {Investigating the Utility of Surprisal from Large Language Models for Speech Synthesis Prosody},
	author       = {Kakouros, Sofoklis and Šimko, Juraj and Vainio, Martti and Suni, Antti},
	year         = 2023,
	month        = jun,
	publisher    = {arXiv},
	number       = {arXiv:2306.09814},
	doi          = {10.48550/arXiv.2306.09814},
	url          = {http://arxiv.org/abs/2306.09814},
	note         = {arXiv:2306.09814 [eess]}
}
@article{Li_Chen_Yan_Shen_Xu_Wu_Zhang_Zhou_Chen_Cheng_etal_2023,
	title        = {ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models},
	author       = {Li, Chenliang and Chen, Hehong and Yan, Ming and Shen, Weizhou and Xu, Haiyang and Wu, Zhikai and Zhang, Zhicheng and Zhou, Wenmeng and Chen, Yingda and Cheng, Chen and Shi, Hongzhu and Zhang, Ji and Huang, Fei and Zhou, Jingren},
	year         = 2023,
	month        = sep,
	publisher    = {arXiv},
	number       = {arXiv:2309.00986},
	doi          = {10.48550/arXiv.2309.00986},
	url          = {http://arxiv.org/abs/2309.00986},
	note         = {arXiv:2309.00986 [cs]}
}
@inproceedings{Liu_Hussain_Sun_Chen_Tan_Li_Lu_Ma_Zhang_2024,
	title        = {Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning},
	author       = {Liu, Shansong and Hussain, Atin Sakkeer and Sun, Chenshuo and Shan, Ying},
	year         = 2024,
	month        = apr,
	booktitle    = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {286–290},
	doi          = {10.1109/ICASSP48485.2024.10447027},
	issn         = {2379-190X},
	url          = {https://ieeexplore.ieee.org/abstract/document/10447027}
}
@article{Liu_Hussain_Wu_Sun_Shan_2024,
	title        = {M$^{2}$UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models},
	author       = {Liu, Shansong and Hussain, Atin Sakkeer and Wu, Qilong and Sun, Chenshuo and Shan, Ying},
	year         = 2024,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2311.11255},
	doi          = {10.48550/arXiv.2311.11255},
	url          = {http://arxiv.org/abs/2311.11255},
	note         = {arXiv:2311.11255 [cs]}
}
@article{Liu_Zhu_Liu_Yuan_Huang_Cui_Liang_Cao_Kong_Plumbley_etal_2025,
	title        = {WavJourney: Compositional Audio Creation With Large Language Models},
	author       = {Liu, Xubo and Zhu, Zhongkai and Liu, Haohe and Yuan, Yi and Huang, Qiushi and Cui, Meng and Liang, Jinhua and Cao, Yin and Kong, Qiuqiang and Plumbley, Mark D. and Wang, Wenwu},
	year         = 2025,
	journal      = {IEEE Transactions on Audio, Speech and Language Processing},
	volume       = 33,
	pages        = {2830–2844},
	doi          = {10.1109/TASLPRO.2025.3574867},
	issn         = {2998-4173}
}
@inproceedings{Liu_Lai_Gao_Cui_Li_Zhu_Lu_Chen_Qiao_Dai_etal_2025,
	title        = {ControlLLM: Augment Language Models with Tools by Searching on Graphs},
	author       = {Liu, Zhaoyang and Lai, Zeqiang and Gao, Zhangwei and Cui, Erfei and Li, Ziheng and Zhu, Xizhou and Lu, Lewei and Chen, Qifeng and Qiao, Yu and Dai, Jifeng and Wang, Wenhai},
	year         = 2025,
	booktitle    = {Computer Vision – ECCV 2024},
	publisher    = {Springer Nature Switzerland},
	address      = {Cham},
	pages        = {89–105},
	doi          = {10.1007/978-3-031-73254-6_6},
	isbn         = {978-3-031-73254-6},
	editor       = {Leonardis, Aleš and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, Gül},
	language     = {en}
}
@inproceedings{Lu_Clark_Lee_Zhang_Khosla_Marten_Hoiem_Kembhavi_2024,
	title        = {Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action},
	author       = {Lu, Jiasen and Clark, Christopher and Lee, Sangho and Zhang, Zichen and Khosla, Savya and Marten, Ryan and Hoiem, Derek and Kembhavi, Aniruddha},
	year         = 2024,
	pages        = {26439–26455},
	url          = {https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Unified-IO_2_Scaling_Autoregressive_Multimodal_Models_with_Vision_Language_Audio_CVPR_2024_paper.html},
	language     = {en}
}
@article{Rubenstein_Asawaroengchai_Nguyen_Bapna_Borsos_Quitry_Chen_Badawy_Han_Kharitonov_etal_2023,
	title        = {AudioPaLM: A Large Language Model That Can Speak and Listen},
	author       = {Rubenstein, Paul K. and Asawaroengchai, Chulayuth and Nguyen, Duc Dung and Bapna, Ankur and Borsos, Zalán and Quitry, Félix de Chaumont and Chen, Peter and Badawy, Dalia El and Han, Wei and Kharitonov, Eugene and Muckenhirn, Hannah and Padfield, Dirk and Qin, James and Rozenberg, Danny and Sainath, Tara and Schalkwyk, Johan and Sharifi, Matt and Ramanovich, Michelle Tadmor and Tagliasacchi, Marco and Tudor, Alexandru and Velimirović, Mihajlo and Vincent, Damien and Yu, Jiahui and Wang, Yongqiang and Zayats, Vicky and Zeghidour, Neil and Zhang, Yu and Zhang, Zhishuai and Zilka, Lukas and Frank, Christian},
	year         = 2023,
	month        = jun,
	publisher    = {arXiv},
	number       = {arXiv:2306.12925},
	doi          = {10.48550/arXiv.2306.12925},
	url          = {http://arxiv.org/abs/2306.12925},
	note         = {arXiv:2306.12925 [cs]}
}
@article{Vyas_Shi_Le_Tjandra_Wu_Guo_Zhang_Zhang_Adkins_Ngan_etal_2023,
	title        = {Audiobox: Unified Audio Generation with Natural Language Prompts},
	author       = {Vyas, Apoorv and Shi, Bowen and Le, Matthew and Tjandra, Andros and Wu, Yi-Chiao and Guo, Baishan and Zhang, Jiemin and Zhang, Xinyue and Adkins, Robert and Ngan, William and Wang, Jeff and Cruz, Ivan and Akula, Bapi and Akinyemi, Akinniyi and Ellis, Brian and Moritz, Rashel and Yungster, Yael and Rakotoarison, Alice and Tan, Liang and Summers, Chris and Wood, Carleigh and Lane, Joshua and Williamson, Mary and Hsu, Wei-Ning},
	year         = 2023,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2312.15821},
	doi          = {10.48550/arXiv.2312.15821},
	url          = {http://arxiv.org/abs/2312.15821},
	note         = {arXiv:2312.15821 [cs]}
}
@article{Wang_Chen_Wu_Zhang_Zhou_Liu_Chen_Liu_Wang_Li_etal_2023,
	title        = {Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers},
	author       = {Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and He, Lei and Zhao, Sheng and Wei, Furu},
	year         = 2023,
	month        = jan,
	publisher    = {arXiv},
	number       = {arXiv:2301.02111},
	doi          = {10.48550/arXiv.2301.02111},
	url          = {http://arxiv.org/abs/2301.02111},
	note         = {arXiv:2301.02111 [cs]}
}
@inproceedings{Wang_Yang_Wu_Zhang_2024,
	title        = {Can Whisper Perform Speech-Based In-Context Learning?},
	author       = {Wang, Siyin and Yang, Chao-Han and Wu, Ji and Zhang, Chao},
	year         = 2024,
	month        = apr,
	booktitle    = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {13421–13425},
	doi          = {10.1109/ICASSP48485.2024.10446502},
	issn         = {2379-190X},
	url          = {https://ieeexplore.ieee.org/abstract/document/10446502}
}
@inproceedings{Wu_Gaur_Chen_Zhou_Zhu_Wang_Li_Liu_Ren_Liu_etal_2023,
	title        = {On Decoder-Only Architecture For Speech-to-Text and Large Language Model Integration},
	author       = {Wu, Jian and Gaur, Yashesh and Chen, Zhuo and Zhou, Long and Zhu, Yimeng and Wang, Tianrui and Li, Jinyu and Liu, Shujie and Ren, Bo and Liu, Linquan and Wu, Yu},
	year         = 2023,
	month        = dec,
	booktitle    = {2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
	pages        = {1–8},
	doi          = {10.1109/ASRU57964.2023.10389705},
	url          = {https://ieeexplore.ieee.org/abstract/document/10389705}
}
@article{Wu_Donahue_Watanabe_Bryan_2024,
	title        = {Music ControlNet: Multiple Time-Varying Controls for Music Generation},
	author       = {Wu, Shih-Lun and Donahue, Chris and Watanabe, Shinji and Bryan, Nicholas J.},
	year         = 2024,
	journal      = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	volume       = 32,
	pages        = {2692–2703},
	doi          = {10.1109/TASLP.2024.3399026},
	issn         = {2329-9304}
}
@article{Yang_Tian_Tan_Huang_Liu_Chang_Shi_Zhao_Bian_Zhao_etal_2024,
	title        = {UniAudio: An Audio Foundation Model Toward Universal Audio Generation},
	author       = {Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Chang, Xuankai and Shi, Jiatong and Zhao, Sheng and Bian, Jiang and Zhao, Zhou and Wu, Xixin and Meng, Helen},
	year         = 2024,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2310.00704},
	doi          = {10.48550/arXiv.2310.00704},
	url          = {http://arxiv.org/abs/2310.00704},
	note         = {arXiv:2310.00704 [cs]}
}
@article{Yu_Song_Lu_He_Tan_Ye_Zhang_Bian_2023,
	title        = {MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models},
	author       = {Yu, Dingyao and Song, Kaitao and Lu, Peiling and He, Tianyu and Tan, Xu and Ye, Wei and Zhang, Shikun and Bian, Jiang},
	year         = 2023,
	month        = oct,
	publisher    = {arXiv},
	number       = {arXiv:2310.11954},
	doi          = {10.48550/arXiv.2310.11954},
	url          = {http://arxiv.org/abs/2310.11954},
	note         = {arXiv:2310.11954 [cs]}
}
@inproceedings{Yu_Tang_Sun_Chen_Tan_Li_Lu_Ma_Zhang_2024,
	title        = {Connecting Speech Encoder and Large Language Model for ASR},
	author       = {Yu, Wenyi and Tang, Changli and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
	year         = 2024,
	month        = apr,
	booktitle    = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {12637–12641},
	doi          = {10.1109/ICASSP48485.2024.10445874},
	issn         = {2379-190X},
	url          = {https://ieeexplore.ieee.org/abstract/document/10445874}
}
@article{Yuan_Lin_Wang_Tian_Wu_Shen_Zhang_Wu_Liu_Zhou_etal_2024,
	title        = {ChatMusician: Understanding and Generating Music Intrinsically with LLM},
	author       = {Yuan, Ruibin and Lin, Hanfeng and Wang, Yi and Tian, Zeyue and Wu, Shangda and Shen, Tianhao and Zhang, Ge and Wu, Yuhang and Liu, Cong and Zhou, Ziya and Ma, Ziyang and Xue, Liumeng and Wang, Ziyu and Liu, Qin and Zheng, Tianyu and Li, Yizhi and Ma, Yinghao and Liang, Yiming and Chi, Xiaowei and Liu, Ruibo and Wang, Zili and Li, Pengfei and Wu, Jingcheng and Lin, Chenghua and Liu, Qifeng and Jiang, Tao and Huang, Wenhao and Chen, Wenhu and Benetos, Emmanouil and Fu, Jie and Xia, Gus and Dannenberg, Roger and Xue, Wei and Kang, Shiyin and Guo, Yike},
	year         = 2024,
	month        = feb,
	publisher    = {arXiv},
	number       = {arXiv:2402.16153},
	doi          = {10.48550/arXiv.2402.16153},
	url          = {http://arxiv.org/abs/2402.16153},
	note         = {arXiv:2402.16153 [cs]}
}
@article{Zhang_Li_Zhang_Zhan_Wang_Zhou_Qiu_2023,
	title        = {SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities},
	author       = {Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
	year         = 2023,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2305.11000},
	doi          = {10.48550/arXiv.2305.11000},
	url          = {http://arxiv.org/abs/2305.11000},
	note         = {arXiv:2305.11000 [cs]}
}
@article{Zhang_Maezawa_Xia_Yamamoto_Dixon_2024,
	title        = {Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing},
	author       = {Zhang, Yixiao and Maezawa, Akira and Xia, Gus and Yamamoto, Kazuhiko and Dixon, Simon},
	year         = 2024,
	month        = aug,
	publisher    = {arXiv},
	number       = {arXiv:2310.12404},
	doi          = {10.48550/arXiv.2310.12404},
	url          = {http://arxiv.org/abs/2310.12404},
	note         = {arXiv:2310.12404 [cs]}
}
@article{Zhuo_Yuan_Pan_Ma_LI_Zhang_Liu_Dannenberg_Fu_Lin_etal_2024,
	title        = {LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT},
	author       = {Zhuo, Le and Yuan, Ruibin and Pan, Jiahao and Ma, Yinghao and LI, Yizhi and Zhang, Ge and Liu, Si and Dannenberg, Roger and Fu, Jie and Lin, Chenghua and Benetos, Emmanouil and Xue, Wei and Guo, Yike},
	year         = 2024,
	month        = jul,
	publisher    = {arXiv},
	number       = {arXiv:2306.17103},
	doi          = {10.48550/arXiv.2306.17103},
	url          = {http://arxiv.org/abs/2306.17103},
	note         = {arXiv:2306.17103 [cs]}
}
@article{Huang_Ren_Huang_Yang_Ye_Zhang_Liu_Yin_Ma_Zhao_2023,
	title        = {Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation},
	author       = {Huang, Jiawei and Ren, Yi and Huang, Rongjie and Yang, Dongchao and Ye, Zhenhui and Zhang, Chen and Liu, Jinglin and Yin, Xiang and Ma, Zejun and Zhao, Zhou},
	year         = 2023,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2305.18474},
	doi          = {10.48550/arXiv.2305.18474},
	url          = {http://arxiv.org/abs/2305.18474},
	note         = {arXiv:2305.18474 [cs]}
}
@article{Hu_Shen_Wallis_Allen-Zhu_Li_Wang_Wang_Chen_2021,
	title        = {LoRA: Low-Rank Adaptation of Large Language Models},
	author       = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	year         = 2021,
	month        = oct,
	publisher    = {arXiv},
	number       = {arXiv:2106.09685},
	doi          = {10.48550/arXiv.2106.09685},
	url          = {http://arxiv.org/abs/2106.09685},
	note         = {arXiv:2106.09685 [cs]}
}
@article{Sinha_Migozzi_Rey_Zhang_2025,
	title        = {Enhancing Audio-Language Models through Self-Supervised Post-Training with Text-Audio Pairs},
	author       = {Sinha, Anshuman and Migozzi, Camille and Rey, Aubin and Zhang, Chao},
	year         = 2025,
	month        = apr,
	publisher    = {arXiv},
	number       = {arXiv:2408.09269},
	doi          = {10.48550/arXiv.2408.09269},
	url          = {http://arxiv.org/abs/2408.09269},
	note         = {arXiv:2408.09269 [cs]}
}
@article{Dettmers_2023_QLoRA,
	title        = {QLoRA: Efficient Finetuning of Quantized LLMs},
	author       = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.14314},
	url          = {https://arxiv.org/abs/2305.14314},
	note         = {arXiv:2305.14314}
}
@article{Shen_Song_Tan_Li_Lu_Zhuang_2023,
	title        = {HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
	author       = {Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
	year         = 2023,
	month        = dec,
	publisher    = {arXiv},
	number       = {arXiv:2303.17580},
	doi          = {10.48550/arXiv.2303.17580},
	url          = {http://arxiv.org/abs/2303.17580},
	note         = {arXiv:2303.17580 [cs]}
}
% ================================================
% PARADIGMS
% ================================================

% RULE-BASED SYSTEMS
@misc{Dugan_1976,
	title        = {Automatic microphone mixer},
	author       = {Dugan, Daniel E.},
	year         = 1976,
	month        = dec,
	url          = {https://patents.google.com/patent/US3992584A},
	note         = {US Patent 3,992,584}
}
@inproceedings{Perez-Gonzalez_Reiss_2013,
	title        = {A knowledge-engineered autonomous mixing system},
	author       = {Pérez-González, Enrique and Reiss, Joshua D.},
	year         = 2013,
	month        = oct,
	booktitle    = {Audio Engineering Society Convention 135},
	url          = {http://www.aes.org/e-lib/browse.cfm?elib=16953}
}
@article{Mansbridge_Finn_Reiss_2012,
	title        = {Implementation and evaluation of autonomous multi-track fader control},
	author       = {Mansbridge, Stuart and Finn, Saoirse and Reiss, Joshua D.},
	year         = 2012,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 60,
	number       = 10,
	pages        = {821--839}
}
% BLACK BOX SYSTEMS
@article{Martinez-Ramirez_Liao_Fabbro_Uhlich_Nagashima_Mitsufuji_2022,
	title        = {Automatic music mixing with deep learning and out-of-domain data},
	author       = {Martínez-Ramírez, Marco A. and Liao, Wei-Hsiang and Fabbro, Giorgio and Uhlich, Stefan and Nagashima, Chihiro and Mitsufuji, Yuki},
	year         = 2022,
	month        = aug,
	publisher    = {arXiv},
	number       = {arXiv:2208.11428},
	doi          = {10.48550/arXiv.2208.11428},
	url          = {http://arxiv.org/abs/2208.11428},
	note         = {arXiv:2208.11428 [eess]}
}
@article{Ramirez_Wang_Smaragdis_Bryan_2021,
	title        = {Differentiable Signal Processing With Black-Box Audio Effects},
	author       = {Ramírez, Marco A. Martínez and Wang, Oliver and Smaragdis, Paris and Bryan, Nicholas J.},
	year         = 2021,
	month        = may,
	publisher    = {arXiv},
	number       = {arXiv:2105.04752},
	doi          = {10.48550/arXiv.2105.04752},
	url          = {http://arxiv.org/abs/2105.04752},
	note         = {arXiv:2105.04752 [eess]}
}
@article{Steinmetz_Pons_Pascual_Serra_2020,
	title        = {Automatic multitrack mixing with a differentiable mixing console of neural audio effects},
	author       = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
	year         = 2020,
	month        = oct,
	publisher    = {arXiv},
	number       = {arXiv:2010.10291},
	doi          = {10.48550/arXiv.2010.10291},
	url          = {http://arxiv.org/abs/2010.10291},
	note         = {arXiv:2010.10291 [eess]}
}
@article{Vanka_Steinmetz_Rolland_Reiss_Fazekas_2024,
	title        = {Diff-MST: Differentiable Mixing Style Transfer},
	author       = {Vanka, Soumya Sai and Steinmetz, Christian and Rolland, Jean-Baptiste and Reiss, Joshua and Fazekas, George},
	year         = 2024,
	month        = jul,
	publisher    = {arXiv},
	number       = {arXiv:2407.08889},
	doi          = {10.48550/arXiv.2407.08889},
	url          = {http://arxiv.org/abs/2407.08889},
	note         = {arXiv:2407.08889 [eess]}
}
% LANGUAGE BRIDGE
@article{Chu_OReilly_Barnett_Pardo_2025,
	title        = {Text2FX: Harnessing CLAP Embeddings for Text-Guided Audio Effects},
	author       = {Chu, Annie and O'Reilly, Patrick and Barnett, Julia and Pardo, Bryan},
	year         = 2025,
	month        = feb,
	publisher    = {arXiv},
	number       = {arXiv:2409.18847},
	doi          = {10.48550/arXiv.2409.18847},
	url          = {http://arxiv.org/abs/2409.18847},
	note         = {arXiv:2409.18847 [eess]}
}
@article{Doh_Koo_Martinez-Ramirez_Liao_Nam_Mitsufuji_2025,
	title        = {Can Large Language Models Predict Audio Effects Parameters from Natural Language?},
	author       = {Doh, Seungheon and Koo, Junghyun and Martínez-Ramírez, Marco A. and Liao, Wei-Hsiang and Nam, Juhan and Mitsufuji, Yuki},
	year         = 2025,
	month        = jul,
	publisher    = {arXiv},
	number       = {arXiv:2505.20770},
	doi          = {10.48550/arXiv.2505.20770},
	url          = {http://arxiv.org/abs/2505.20770},
	note         = {arXiv:2505.20770 [cs]}
}
@article{Lai_Hung_Zhu_Wang_Sheu_Juang_2022,
	title        = {A Low-Cost Smart Digital Mixer System Based on Speech Recognition},
	author       = {Lai, Shin-Chi and Hung, Ying-Hsiu and Zhu, Yi-Chang and Wang, Szu-Ting and Sheu, Ming-Hwa and Juang, Wen-Ho},
	year         = 2022,
	month        = feb,
	journal      = {Electronics},
	volume       = 11,
	number       = 4,
	pages        = 604,
	doi          = {10.3390/electronics11040604},
	issn         = {2079-9292},
	rights       = {https://creativecommons.org/licenses/by/4.0/},
	language     = {en}
}
@article{Pardo_Cartwright_Seetharaman_Kim_2019,
	title        = {Learning to Build Natural Audio Production Interfaces},
	author       = {Pardo, Bryan and Cartwright, Mark and Seetharaman, Prem and Kim, Bongjun},
	year         = 2019,
	month        = aug,
	journal      = {Arts},
	volume       = 8,
	number       = 3,
	pages        = 110,
	doi          = {10.3390/arts8030110},
	issn         = {2076-0752},
	rights       = {https://creativecommons.org/licenses/by/4.0/},
	language     = {en}
}
@article{Venkatesh_Moffat_Miranda_2022,
	title        = {Word Embeddings for Automatic Equalization in Audio Mixing},
	author       = {Venkatesh, Satvik and Moffat, David and Miranda, Eduardo Reck},
	year         = 2022,
	month        = nov,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 70,
	number       = 9,
	pages        = {753–763},
	doi          = {10.17743/jaes.2022.0047},
	issn         = 15494950,
	language     = {en}
}
@article{Melechovsky_Mehrish_Herremans_2025,
	title        = {SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering},
	author       = {Melechovsky, Jan and Mehrish, Ambuj and Herremans, Dorien},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	number       = {arXiv:2508.03448},
	doi          = {10.48550/arXiv.2508.03448},
	url          = {http://arxiv.org/abs/2508.03448},
	note         = {arXiv:2508.03448 [eess]}
}
@article{Yin_Fu_Zhao_Li_Sun_Xu_Chen_2024,
	title        = {A survey on multimodal large language models},
	author       = {Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
	year         = 2024,
	month        = nov,
	journal      = {National Science Review},
	volume       = 11,
	number       = 12,
	pages        = {nwae403},
	doi          = {10.1093/nsr/nwae403},
	issn         = {2095-5138, 2053-714X},
	rights       = {https://creativecommons.org/licenses/by/4.0/},
	language     = {en}
}
@article{Chourdakis_Reiss_2017,
	title        = {A Machine-Learning Approach to Application of Intelligent Artificial Reverberation},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2017,
	month        = feb,
	journal      = {Journal of the Audio Engineering Society},
	volume       = 65,
	number       = {1/2},
	pages        = {56–65},
	doi          = {10.17743/jaes.2016.0069},
	issn         = 15494950,
	language     = {en}
}
@article{waveunet,
	title        = {Automatic music signal mixing system based on one-dimensional Wave-U-Net autoencoders},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2022,
	doi          = {10.1186/s13636-022-00266-3},
	url          = {https://www.researchgate.net/publication/366902955_Automatic_music_signal_mixing_system_based_on_one-dimensional_Wave-U-Net_autoencoders},
	abstractnote = {PDF | The purpose of this paper is to show a music mixing system that is capable of automatically mixing separate raw recordings with good quality... | Find, read and cite all the research you need on ResearchGate},
	language     = {en}
}
@misc{semantic-mixing,
	title        = {A Semantic Approach To Autonomous Mixing},
	author       = {Chourdakis, Emmanouil and Reiss, Joshua},
	year         = 2016,
	url          = {https://www.researchgate.net/publication/273574043_A_Semantic_Approach_To_Autonomous_Mixing},
	abstractnote = {PDF | In this work, we give an overview of current automatic mixing approaches, and note the absence of using high-level, semantic knowledge to inform... | Find, read and cite all the research you need on ResearchGate},
	language     = {en}
}
